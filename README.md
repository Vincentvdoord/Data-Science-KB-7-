# DataScience (KB-74)
Dit is het Github portfolio van Vincent van den Oord (15073041). Hierin zal gereflecteerd/gedocumenteerd worden. De focus hierbij ligt bij mij zelf, wat was mijn bijdrage aan het project en belangrijk: wat heb ik geleerd/ervaren. 

## Portfolio Indeling
- [1.0 De introductie](#10-de-introductie)
  - [1.1 Keuze onderbouwing](#11-keuze-onderbouwing)
  - [1.2 Persoonlijke leerdoelen](#12-persoonlijke-leerdoelen)
  - [1.3 Rol binnen de groep](#13-rol-binnen-de-groep)
  - [1.4 Ortho Eyes opdracht](#14-ortho-eyes-opdracht)
- [2.0 Persoonlijke ontwikkeling](#20-persoonlijke-ontwikkeling)
  - [2.1 DataCamp](#21-datacamp)
  - [2.2 Coursera](#22-coursera)
  - [2.3 Spark Assignments](#23-spark-assignments)
  - [2.3 Jargon](#24-jargon)
- [3.0 Gedurende het project](#30-gedurende-het-project)
  - [3.1 Classifiers](#31-classifiers)
  - [3.2 Oefeningen vergelijken](#32-oefeningen-vergelijken)
  - [3.3 Cleanen van de data](#33-cleanen-van-de-data)
  - [3.4 Huidige stand visueel](#34-huidige-stand-visueel)
  - [3.5 Presentaties](#35-presentaties)
  - [3.6 Overig](#36-overig)
- [4.0 Reflectie](#40-reflectie)
  - [4.1 Reflecteren op de leerdoelen](#41-reflecteren-op-de-leerdoelen)

## 1.0 De Introductie
In dit hoofdstuk zullen allerlei globale zaken aanbod komen. Onder andere waarom ik voor deze minor heb gekozen en wat mijn rol was binnen dit project.

### 1.1 Keuze onderbouwing
Ik volg de opleiding ICT (Business IT & Management) op de Haagse Hogeschool in Den Haag. Daar krijgen we vakken die te maken hebben met data (IT) en vakken die met bedrijfskunde te maken hebben (Business & Management). Naar mijn idee bevatte ik nog (te) weinig technische kennis. Ik wist dat deze minor daardoor ook extra zwaar voor mij zou zijn. Ik wist dat ik eraan moest trekken in de avonden door zou moeten gaan en er meer energie in moet steken dan de anderen. Toch heb ik voor deze minor gekozen en zal ik de komende 20 weken mijn best doen om er het beste van te maken en zoveel mogelijk te leren.  

### 1.2 Persoonlijke leerdoelen
De reden dat ik gekozen heb voor deze minor is omdat ik nieuwe dingen wilde leren. Onderstaand mijn persoonlijke leerdoelen voor de komende 20 weken.
 1. Het leren programmeren in Python
 2. Ervaring krijgen met het verwerken van 'Big Data'
 3. De basis van Machine Learning begrijpen/toepassen
 4. Meer technische kennis verkrijgen
 
### 1.3 Rol binnen de groep
Normaliter neem ik de leidende rol in projecten. Omdat ik dusdanig weinig kennis had van Data Science heb ik besloten om dat niet gelijk te doen in dit project. Ik heb de eerste weken gekeken naar iedereen zijn sterktes om zo ons multidisciplinaire team te laten slagen. Na een aantal weken zijn we de taken op elkaars sterktes gaan indelen:

- Luke: meest technische van de groep, het meeste programmeer werk is voor hem
- Rogier: meest wiskundige van de groep, ingewikkelde wiskundige vraagstukken kon hij oplossen
- Kasper: goed in literatuuronderzoek/schrijven van paper, neemt hij grotendeels voor zijn rekening
- Vincent(ik): coördinerende rol en bijspringen waar nodig

Omdat ik redelijk ervaren ben met photoshop heb ik al het design werk opgepakt. Het presentatie template ontworpen en allerlei afbeeldingen gemaakt die relevant zijn voor ons project. Deze zullen geheid aan bod komen in mijn portfolio. 

### 1.4 Ortho Eyes opdracht
Voordat specialisten een diagnose kunnen stellen bij een patient moeten de patienten in de praktijk meerdere oefeningeng uit te voeren om de conditie van de schouder te kunnen achter te halen. Als projectgroep willen wij onderzoeken of het mogelijk is om een diagnose te stellen op basis van de gegenereerde data. 

De data die beschikbaar is, is van echte patiënten. Deze patiënten hebben 1 of meerdere oefeningen uitgevoerd. Als projectgroep hebben wij deze data ontvangen en geanalyseerd. 

Onderstaand de aanpak van ons project, deze heb ik gemaakt.

<details><summary> Aanpak (Afbeelding)</summary>
  <img src="https://github.com/Vincentvdoord/Data-Science-KB-74/blob/master/Afbeeldingen/aanpak%20DS%20ortho.png?raw=true" alt="alt text"></details>
 

## 2.0 Persoonlijke ontwikkeling
Voor mij is binnen het project dit het belangrijkste. Ik wil zoveel mogelijk leren. Als eerste heb ik een wetenschappelijk artikel gelezen om meer informatie over de context te vergaren het artikel dat ik gelezen heb: [(De Groot, 1999)](https://github.com/Vincentvdoord/Data-Science-KB-74/blob/master/DeGroot_1999.pdf)

## 2.4 Jargon
Tijdens ons onderzoek heb ik veel nieuwe begrippen geleerd. Onderstaand een opsomming van de begrippen die tijdens ons project aanbod kwamen.


**Raw/ruwe data** - Ruwe sensor data met locatie en rotatie van de sensoren

**Cleaned data** - Cleaned data is door het LUMC verwerkte ruwe data, in deze data zijn alle sensor locaties weg verwijderd data relatief van elkaar weergegeven d.m.v. hoeken

**Super cleaned data** - De super cleaned data is de door ons schoongemaakte cleaned data, voornamelijk is het begin en eind weggehaald. Soms is de oefening in 2 delen gesplits als bleek dat de oefening 2 maal was uitgevoerd

Naast ons project jargon zijn er ook termen die gebruikt worden om dit medisch gebied, deze zijn hieronder te zien. Dit plaatje heb ik zelf gemaakt.In de afbeelding te zien; de sensoren met haar nummers. Ook de latijnse namen die gebruikt worden door de artsen met vertaling staan erin. Met een ster aangegeven staan de gegevens die berekend worden en enkel te zien is in de gecleande data.

<details><summary> Medisch Jargon (Afbeelding)</summary>
  <img src="https://github.com/Vincentvdoord/Data-Science-KB-74/blob/master/Afbeeldingen/Ortho%20eyes.jpg" alt="alt text"></details>
    
>Thorax - Borstkas / Clavicula - Sleutelbeen / Scapula - Schouderblad / Humerus - Bovenarm / Olecranon - Elleboog

### 2.1 Datacamp
Om mijn persoonlijke doel 1 (Het leren programmeren in Python) te behalen is er vanaf dag 1 fanatiek gewerkt aan Datacamp. Omdat ik in het begin zo graag Python wilde leren was ik er elke dag fanatiek mee bezig. Elke dag wel even wat oefenen op Datacamp. Ik heb dit ruim 40 dagen volgehouden. Want ik vond het ook leuk!

<details><summary> Datacamp streak (Screenshots)</summary>
  <img src="https://i.imgur.com/7gz2IMp.jpg" alt="alt text" width="550" height="170">" 
  <img src="https://i.imgur.com/PqDiPhG.jpg" alt="alt text" width="550" height="170">
</details>

Binnen de gestelde tijd zijn alle noodzakelijke Datacamp courses afgerond.

<details><summary> Datacamp Evidance (Screenshot)</summary>
  <img src="https://i.imgur.com/izapVDF.png" alt="alt text"></details>
  
Naast de noodzakelijke Datacamp courses zijn er ook een aantal extra courses/chapters gemaakt. Omdat ik het niet over mijn hart kon krijgen om een course voor de helft te maken (wat voldoende zou zijn). 

### 2.2 Coursera
Op Coursera zijn alle verplichte Coursera courses gevolgd. Enkel de verplichte courses en quizzes zijn gedaan omdat het vrij lastig was en behoorlijk wat theorie. Tevens was er niet meer nodig voor het project. Ook mijn persoonlijke doel 3 (De basis van Machine Learning begrijpen/toepassen) te behalen worden de Coursera courses gevolgt. Onderstaand een screenshots als bewijsvoering.

<details><summary> Coursera Evidance (Screenshot)</summary> 
    <img src="https://github.com/Vincentvdoord/Data-Science-KB-74/blob/master/Afbeeldingen/Coursera%20Full%20Page%202.png?raw=true" alt="alt text"></details>

### 2.3 Spark Assignments
Tijdens ons project/onderzoek (Ortho Eyes) was het gebruik van Spark niet noodzakelijk. Het runnen van geschreven notebooks duurde maximaal 10 minuten gezien er niet werd gewerkt met enorme hoeveelheden data. Omdat het runnen van deze notebooks al niet lang duurde zouden we niet heel veel voordeel kunnen halen uit het gebruik van Spark. Om deze reden hebben we de Spark Assignments dan ook niet gemaakt.

## 3.0 Gedurende het project
In dit hoofdstuk is staat alles beschreven wat ik gedaan hebt tijdens het project of waar ik een bijdrage aan geleverd heb. Tijdens het project heb ik zoveel mogelijk verschillende werkzaamheden uitgevoerd om zo mijn kennis te verbreden. 

### 3.1 Classifiers
Binnen het project heb ik individueel en in samenwerking met menig classifier gebouwd. Binnen de dataset waren er 4 categorieën die onderscheiden konden worden. De uitdaging was om een accuracy van 90% of hoger te halen. Vanaf  90% was het redelijk betrouwbaar voor het LUMC. Alle resultaten van de classifiers staan onder het kopje 'Resultaten' in [ons paper](https://github.com/Vincentvdoord/Data-Science-KB-74/blob/master/paper_ortho_eyes.pdf)

**Classifier 1 vs all**

De eerste classifier die ik heb gemaakt in dit project is de één tegen de rest classifier, waar één categorie tegen de andere categorieën vergeleken wordt. Dit was gedaan op sample niveau wat in de paper wordt uitgelegd. Het maken van de classifier is eerst gedaan met behulp van de tutorial van J. Vuurens. Waarna ik het omgebouwd heb in SKlearn voor betere performance. Met deze classifier konden we cat1 en cat4 onderscheiden van de rest. Maar 2 en 3 nog niet van elkaar.

Deze classifier is helaas dusdanig omgebouwd dat ik de originele niet meer bezit.

**KNN Classifier**

In het kader van proberen en leren. Heb ik samen met Kasper de KNN classifier gemaakt. Deze is behandeld in de datacamp courses en wij wilden het graag op onze data loslaten. Het werkte alsvolgt. Het script gaat 10x een classifier trainen en testen (N= 1-10). Met de beste waarde voor N trainen we dan de uiteindelijke classifier. Het was een goede oefening maar niet heel betrouwbaar. 

[KNN Classifier](https://github.com/Vincentvdoord/Data-Science-KB-74/blob/master/Scripts/classifier%20cat%204%20versie%202.1.ipynb)

**Classifier Cat 2 vs 3**

Omdat de eerste classifier nog geen goede resultatent gaf kregen we het advies in de wekelijke presentatie om een de classifier te versimpelen en enkel cat2 tegen cat3 uit te zetten. Met de resultaten van deze classifier (te vinden in de paper) hebben we gezien dat hoe groter het verschil tussen de categorieën, hoe preciseer we kunnen clasificeren. De classifier werkt door twee categorieën met elkaar te vergelijken, bijvoorbeeld categorie 1 met 2 (True vs False). Deze sample niveau classifier is samen met Luke gemaakt.

[Classifier 2vs 3](https://github.com/Vincentvdoord/Data-Science-KB-74/blob/master/Scripts/Classifier%202%20vs%203%20v0.2.ipynb)

**Classifier (cat1 vs 2 .ABS().MAX)**

Deze classifier is de eerste poging geweest om tot een patiënt niveau classifier te komen. Om van sample niveau classifiers af te stappen hadden we een manier nodig om parameters van een patiënt te maken. Als eerste patiënt classifier hebben we daarom gekozen om de maximale hoeken mee te nemen als waardes voor de classifier. Het idee hierachter was om de maximale beweging van de patiënt te meten, om te zien hoever hij zijn arm bijvoorbeeld omhoog kon bewegen. Daarna probeerde we de .ABS().MAX()

Deze patiënt niveau classifier is samen met Luke gemaakt. [Patient niveau classifier](https://github.com/Vincentvdoord/Data-Science-KB-74/blob/master/Scripts/classifier%20patient%20niveau%20versie%200.1.ipynb)

Vervolgens hadden we nog een 1 vs all classifier gemaakt op patient niveau. [Patient niveau classifier 1 v all](https://github.com/Vincentvdoord/Data-Science-KB-74/blob/master/Scripts/classifier%20patient%20niveau%20versie%200.3%20-%20less%20is%20more.ipynb)

Het probleem waar we gelijk tegen aan liepen was dat de test set erg weinig patienten bevatte. Daardoor waren de resultaten niet betrouwbaar. Met name in Cat4 hadden we maar 1 patient in de testset.

**Classifier XYZ energie**

Als laatste heb ik de XYZ energie classifier gebouwd. Deze onderscheid zich van de andere classifiers omdat ik bij deze classifier gebruik heb gemaakt van de oppervlakte berekeningen van mijn project genoten. Ik heb het in een classifier gedaan en heel veel verschillende soorten combinatie geprobeerd.

XYZ energie bij elkaar optellen 
XYZ energie apart meegeven
X,Y energie (Z weglaten)

Helaas was het resultaat van al deze varianten niet goed (<50%). [XYZ Energie classifier](https://github.com/Vincentvdoord/Data-Science-KB-74/blob/master/Scripts/Classifier%20oppervlakte.ipynb)

### 3.2 Oefeningen vergelijken
In alle categorieen zijn er oefeningen uitgevoerd maar ze hadden allerlei verschillende getallen. We wilde onderzoeken of een oefening 2 uit categorie4 hetzelfde is als een oefening2 uit categorie3. Als we dit hadden uitgezocht konden we een gerichtere classifier maken.

Ik heb samen met Kasper dit script gemaakt. Die alle oefeningen uit verschillende categorieen naast elkaar zet. Zo konden we in grote lijnen zien of het dezelfde oefening is.

<details><summary> Oefeningen vergelijken script (Screenshot)</summary>
  <img src="https://github.com/Vincentvdoord/Data-Science-KB-74/blob/master/Afbeeldingen/%20Vergelijken%20van%20de%20oefeningen.png">"alt="alt text"></details>
  
Het script is hier te vinden. Het was vrij lastig om 4 tabellen naast elkaar te krijgen, maar dat was uiteindelijk gelukt. [Zoek de verschillen](https://github.com/Vincentvdoord/Data-Science-KB-74/blob/master/Scripts/Zoek%20de%20verschillen%20v2.1%20-%20luke.ipynb)

### 3.3 Cleanen van de Data
In zijn totaliteit moesten er 1500 oefeningen gecleaned worden. Dit hebben wij als groep gedaan. Het python script hiervoor is geschreven door Luke. Ik had het idee hiervoor bedacht om het bestand te verwijderen als het was verwerkt en het ergens anders op te slaan. Hierdoor konden we met meerdere personen eraan werken en was het mogelijk om op een later moment te hervatten. 

<details><summary> Cleanen van de data makkelijk voorbeeld (Screenshot)</summary>
  <img src="https://github.com/Vincentvdoord/Data-Science-KB-74/blob/master/Afbeeldingen/Datasplitter.png">"alt="alt text"></details>

Zoals te zien is in de bovenstaande afbeelding is de destbetreffende oefening 2 maal uitgevoerd. Het was dan de bedoeling dat het midden werd bepaald en het begin en eind (ruis) werd verwijderd. Als alle 1500 oefeningen eruit zagen als bovenstaand was het makkelijk maar helaas zaten er ook ingewikkeldere oefeningen tussen

<details><summary> Cleanen van de data moeilijk voorbeeld (Screenshot)</summary>
  <img src="https://github.com/Vincentvdoord/Data-Science-KB-74/blob/master/Afbeeldingen/Datasplitter2.png?raw=true>"alt="alt text"></details>
  
In de laatste week bleek dat de apart gezette testset nog gecleaned moest worden. Dit heb ik voor mijn rekening genomen (circa 140 oefeningen extra)

### 3.4 Huidige stand visueel
Na verloop van tijd had iedereen zoveel dingen gemaakt. Iedereen had in zijn mappen een x aantal scripts staan en we deden eigenlijk maar wat. Ik heb toen besloten om het gehele project te visualiseren. Met als belangrijkste uitgangspunten: Waar staan we nu?, Waar zijn we mee bezig?, Wat willen we nog bereiken?

<details><summary> Project Visualisatie (Afbeelding)</summary>
  <img src="https://github.com/Vincentvdoord/Data-Science-KB-74/blob/master/Afbeeldingen/Projectaanpak.png?raw=true" alt="alt text"></details>

In de afbeelding is te zien wat we al gedaan hadden en waar iedereen mee bezig was. Rogier was bezig met het manipuleren van de parameters. Luke was bezig met een neuraalnetwerk en Kasper was zich aan het inlezen over dropouts. In deze afbeelding is het dan in 1 opzicht duidelijk waar in het project iedereen aan het 'sleutelen' was. Zo wist iedereen weer wat iedereen aan het doen was en waarvoor.

## 3.5 Presentaties
Iedere vrijdag dient er gepresenteerd te worden. Omdat er elke week een presentatie gemaakt moest worden leek het mij handig om hier een procesje voor in te richten. Dat was als volgt: Donderdag 12:00 presentatie maken en vrijdag ochtend 11:00 met Tony de presentatie langslopen. Dit pakte elke week goed uit.

Ik heb meegeholpen aan het maken van elke presentatie, behalve die van week8. De weken dat ik daadwerkelijk gepresenteerd heb is week 3/6/11/12*. Daarna wilde Kasper vrijwillig alle presentaties doen en dat was naar mijn idee prima.

*Deze heb ik onverwachts moeten opvangen in het kader van ziekte/afwezigheid. 

Ik heb wel meegeholpen aan de presentaties die kasper gegeven heeft.

[Presentaties](https://github.com/Vincentvdoord/Data-Science-KB-74/upload/master/Presentaties)


### 3.6 Overig
Begin oktober was er een CvB-borrel van de faculteit IT&D op de Haagse Hogeschool. Tijdens deze borrel hebben wij aan andere onderwijzers uitgelegd wat het doel is van dit project en waar wij precies mee bezig zijn. Dit hebben wij met behulp van [deze poster](https://github.com/Vincentvdoord/Data-Science-KB-74/blob/master/Afbeeldingen/POSTER1.png) uitgelegd die ik gemaakt heb met Kasper. Ik was er tijdens die borrel ook bij en heb aan veel geïnteresseerde docenten uitgelegd over ons project.

Dit is een impressie van onze 'presentatie' bij de CvB-borrel.

<details><summary> CvB - borrel (Groepsfoto)</summary>
  <img src="https://raw.githubusercontent.com/vdhoofdk/Data-Science-KB-74/master/Other/cvb-borrel.jpg"></details>

## 4.0 Reflectie
Als ik terugkijk op de afgelopen 20 weken is de tijd snel gegaan. In het begin had ik nog enige twijfel bij deze minor. Dat kwam voornamelijk door het programmeer werk. Achteraf bleek dat de wiskunde erachter ingewikkelder was dan het programmeren zelf. 

Ook moest ik erg wennen aan de manier van werken. Vanuit mijn opleiding hebben we veel te maken gehad met projectmanagement maar nooit echt onderzoek gedaan op deze manier. Je kan heel moeilijk ver voor uit plannen want je weet niet precies wat er gaat gebeuren. Dat was wennen. 

### 4.1 Reflecteren op de leerdoelen
Om terug te komen op de leerdoelen.

**1. Het leren programmeren in Python**
Dit doel heb ik naar mijn idee naar behoren gehaald. Het is niet dat ik de snelste/beste Python programmeur ben, maar als eerste programmeertaal waar ik kennis van heb mogen nemen kan ik data inlezen bewerken en analyseren.

**2. Ervaring krijgen met het verwerken van 'Big Data'**
Wat ik hier voornamelijk van heb geleerd is dat het ingewikkelder is dan het lijkt. Met 'verwerken' bedoelde ik van nietszeggende data naar informatie. Ons gehele project stond daar in het kader van en ook dit doel is gehaald.

**3. De basis van Machine Learning begrijpen/toepassen**
De basis van machine learning was vanaf dag 1 lastig voor mij, laat staan het toepassen. Maar vlak voor de toets toen ik ervoor ging zitten zag ik het licht. Als ik het nog een keer over zou doen zal ik eerder in het traject de tijd nemen om dit te snappen dat zal veel tijd/stress besparen.

**4. Meer technische kennis verkrijgen**
Als programmeren/jupyter servers/machine learning valt onder technische kennis dan is het zeker gelukt om mijn kennis te verbreden.
