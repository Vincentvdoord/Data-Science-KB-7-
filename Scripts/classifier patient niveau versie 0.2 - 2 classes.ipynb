{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HeaderMaker(PatientFile):\n",
    "    df_cleaned = pd.read_csv('/datc/ortho/Cleaning/step2/' + PatientFile, header=None)\n",
    "\n",
    "    df_cleaned = df_cleaned.rename(columns={0: \"thorax_r_x\", 1: \"thorax_r_y\", 2: \"thorax_r_z\"})\n",
    "    df_cleaned = df_cleaned.rename(columns={3: \"clavicula_r_x\", 4: \"clavicula_r_y\", 5: \"clavicula_r_z\"})\n",
    "    df_cleaned = df_cleaned.rename(columns={6: \"scapula_r_x\", 7: \"scapula_r_y\", 8: \"scapula_r_z\"})\n",
    "    df_cleaned = df_cleaned.rename(columns={9: \"humerus_r_x\", 10: \"humerus_r_y\", 11: \"humerus_r_z\"})\n",
    "    df_cleaned = df_cleaned.rename(columns={12: \"ellebooghoek_r\"})\n",
    "    df_cleaned = df_cleaned.rename(columns={15: \"thorax_l_x\", 16: \"thorax_l_y\", 17: \"thorax_l_z\"})\n",
    "    df_cleaned = df_cleaned.rename(columns={18: \"clavicula_l_x\", 19: \"clavicula_l_y\", 20: \"clavicula_l_z\"})\n",
    "    df_cleaned = df_cleaned.rename(columns={21: \"scapula_l_x\", 22: \"scapula_l_y\", 23: \"scapula_l_z\"})\n",
    "    df_cleaned = df_cleaned.rename(columns={24: \"humerus_l_x\", 25: \"humerus_l_y\", 26: \"humerus_l_z\"})\n",
    "    df_cleaned = df_cleaned.rename(columns={27: \"ellebooghoek_l\"})\n",
    "    \n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "Patients = {}\n",
    "testdataurl = '/datc/ortho/Cleaning/step2/'\n",
    "for PatientFile in listdir(testdataurl):\n",
    "    if ('meting' not in PatientFile):\n",
    "        print('Skipping: %s' % PatientFile)\n",
    "        # Skip this iteration\n",
    "        continue\n",
    "    Splitted = PatientFile.split('_')\n",
    "    Patient = Splitted[0] + '_' + Splitted[1]\n",
    "\n",
    "    Data = HeaderMaker(PatientFile)\n",
    "    MaxDict = Data.max().to_dict() # .abs() for absolute numbers\n",
    "    \n",
    "    if(Patient not in Patients.keys()):\n",
    "        Patients[Patient] = MaxDict\n",
    "        Patients[Patient]['GroundTruth'] = Splitted[0].split('Cat')[1]\n",
    "        Patients[Patient]['Bias'] = 0\n",
    "        continue\n",
    "    \n",
    "    for key in MaxDict.keys():\n",
    "        Patients[Patient][key]= max(Patients[Patient][key],MaxDict[key])\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "            \n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(Patients, orient='index')\n",
    "# print(df.columns.values)\n",
    "df = df[['Cat3' in index or 'Cat4' in index for index in df.index]] # Welke colommen wil je houden\n",
    "\n",
    "df['TrueFalse'] = ['4' == i for i in df['GroundTruth']]\n",
    "\n",
    "# print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xcolumns = ['Bias']\n",
    "Xcolumns.extend(['thorax_r_x', 'thorax_r_y', 'thorax_r_z', 'clavicula_r_x', 'clavicula_r_y',\n",
    " 'clavicula_r_z', 'scapula_r_x', 'scapula_r_y', 'scapula_r_z', 'humerus_r_x',\n",
    " 'humerus_r_y', 'humerus_r_z', 'ellebooghoek_r', 'thorax_l_x',\n",
    " 'thorax_l_y', 'thorax_l_z', 'clavicula_l_x', 'clavicula_l_y', 'clavicula_l_z',\n",
    " 'scapula_l_x', 'scapula_l_y', 'scapula_l_z', 'humerus_l_x', 'humerus_l_y',\n",
    " 'humerus_l_z', 'ellebooghoek_l'])\n",
    "\n",
    "# X = df[Xcolumns]\n",
    "# y = df[['GroundTruth']]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3' '4']\n"
     ]
    }
   ],
   "source": [
    "print(df['GroundTruth'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Percentage test: 0.2\n"
     ]
    }
   ],
   "source": [
    "def Patient_test_split(dataframe, xcol, ycol, Percentage):\n",
    "    allIndex = np.unique(df.index.tolist()) # Get all unique patients id's\n",
    "    random.seed(2) # Set random seeed so the answer is the same\n",
    "    \n",
    "    PercentageIndex = []\n",
    "    for i in df['GroundTruth'].unique(): # Cycle through each categorie (only cycles through the ones that are present)\n",
    "        CatPatients = np.array([i.split('_')[0].split('Cat')[1] for i in allIndex])\n",
    "        CatPatients = CatPatients[CatPatients==i]\n",
    "        \n",
    "        AmountItems = len(CatPatients)\n",
    "        AmountRandom = math.floor(AmountItems*Percentage)\n",
    "        PercentageIndex.extend(random.sample(list(CatPatients), AmountRandom))        \n",
    "        \n",
    "    AmountItems = len(allIndex)\n",
    "    AmountRandom = math.floor(AmountItems*Percentage)\n",
    "    \n",
    "    PercentageIndex = random.sample(list(allIndex), AmountRandom)\n",
    "    \n",
    "    Percentagedf = df[xcol][df.index.isin(PercentageIndex)]\n",
    "    Percentagey = df[ycol][df.index.isin(PercentageIndex)]\n",
    "    \n",
    "    Testdf = df[xcol][~df.index.isin(PercentageIndex)]\n",
    "    Testy = df[ycol][~df.index.isin(PercentageIndex)]\n",
    "    print('Final Percentage test: %s' % (len(Testdf)/len(Percentagedf)))\n",
    "    return (Percentagedf, Testdf, Percentagey, Testy)\n",
    "\n",
    "X_train, X_test, y_train, y_test = Patient_test_split(df, Xcolumns, 'TrueFalse', 0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 7\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/jupyterhub/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.0152968  -0.02915241  0.00997657 -0.08927448 -0.00305566\n",
      " -0.02462792 -0.0537537   0.10549853  0.08645274  0.05748671 -0.1625125\n",
      "  0.04485686  0.00084766  0.0152968  -0.01521135 -0.02504779 -0.07120407\n",
      "  0.00227123  0.07995811 -0.05293983  0.13337942  0.03015809 -0.05717823\n",
      " -0.02731522  0.03589297 -0.00023451]\n",
      "1.0\n",
      "Cat3_pat10    False\n",
      "Cat3_pat12    False\n",
      "Cat3_pat16    False\n",
      "Cat3_pat20    False\n",
      "Cat3_pat33    False\n",
      "Cat3_pat35    False\n",
      "Cat4_pat20     True\n",
      "Name: TrueFalse, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "y_pred = lr.predict(X_test)\n",
    "print(lr.coef_[0])\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             pos  neg\n",
      "0  pred pos    1    0\n",
      "1  pred neg    0    6\n",
      "\n",
      "recall:  1.0\n",
      "precision:  1.0\n",
      "accuracy:  1.0\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, \\\n",
    "recall_score, precision_score, accuracy_score, confusion_matrix\n",
    "\n",
    "y_true = y_test\n",
    "y_pred =lr.predict(X_test)\n",
    "\n",
    "TN, FP, FN, TP = confusion_matrix(y_true, y_pred).ravel()\n",
    "# print(y_true)\n",
    "# tabel printen\n",
    "\n",
    "# print('Informationi matrix %s' % cat)\n",
    "tab = [[\"pred pos\", TP, FP], [\"pred neg\", FN, TN]]\n",
    "print(pd.DataFrame(tab, columns=[\"\", \"pos\", \"neg\"]))\n",
    "print()\n",
    "print(\"recall: \", recall_score(y_true, y_pred))\n",
    "print(\"precision: \", precision_score(y_true, y_pred))\n",
    "print(\"accuracy: \", accuracy_score(y_true, y_pred))\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False      1.000     1.000     1.000         6\n",
      "        True      1.000     1.000     1.000         1\n",
      "\n",
      "   micro avg      1.000     1.000     1.000         7\n",
      "   macro avg      1.000     1.000     1.000         7\n",
      "weighted avg      1.000     1.000     1.000         7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_true, y_pred, digits=3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
