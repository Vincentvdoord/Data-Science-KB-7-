{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import time\n",
    "%matplotlib notebook\n",
    "import seaborn as sns\n",
    "from scipy.special import expit as logit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.special import expit as sigmoid # is more stable in case of overflows\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, \\\n",
    "recall_score, precision_score, accuracy_score, confusion_matrix\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-8613c1500ec0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_cleaned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/datc/ortho/'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m';'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_cleaned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/jupyterhub/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/jupyterhub/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/jupyterhub/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/jupyterhub/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/jupyterhub/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": [
    "df_cleaned = pd.read_csv('/datc/ortho/',  sep= ';')\n",
    "print(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# bereken symmetrie\n",
    "df_cleaned['clavicula_x_dif'] = np.absolute(df_cleaned['clavicula_l_x'] - df_cleaned['clavicula_r_x'])\n",
    "df_cleaned['clavicula_y_dif'] = np.absolute(df_cleaned['clavicula_l_y'] - df_cleaned['clavicula_r_y'])\n",
    "df_cleaned['clavicula_z_dif'] = np.absolute(df_cleaned['clavicula_l_z'] - df_cleaned['clavicula_r_z'])\n",
    "\n",
    "df_cleaned['scapula_x_dif'] = np.absolute(df_cleaned['scapula_l_x'] - df_cleaned['scapula_r_x'])\n",
    "df_cleaned['scapula_y_dif'] = np.absolute(df_cleaned['scapula_l_y'] - df_cleaned['scapula_r_y'])\n",
    "df_cleaned['scapula_z_dif'] = np.absolute(df_cleaned['scapula_l_z'] - df_cleaned['scapula_r_z'])\n",
    "\n",
    "df_cleaned['humerus_x_dif'] = np.absolute(df_cleaned['humerus_l_x'] - df_cleaned['humerus_r_x'])\n",
    "df_cleaned['humerus_y_dif'] = np.absolute(df_cleaned['humerus_l_y'] - df_cleaned['humerus_r_y'])\n",
    "df_cleaned['humerus_z_dif'] = np.absolute(df_cleaned['humerus_l_z'] - df_cleaned['humerus_r_z'])\n",
    "\n",
    "# hulp array, met alle parameters die voor de classifier gebruikt worden, je kan hier alles in doen wat je wilt\n",
    "param = [ \\\n",
    "          'humerus_l_x', 'humerus_l_y', 'humerus_l_z', 'humerus_r_x', 'humerus_r_y', 'humerus_r_z', \\\n",
    "          'clavicula_l_x', 'clavicula_l_y', 'clavicula_l_z', 'clavicula_r_x', 'clavicula_r_y', 'clavicula_r_z', \\\n",
    "          'scapula_l_x', 'scapula_l_y', 'scapula_l_z', 'scapula_r_x', 'scapula_r_y', 'scapula_r_z', \\\n",
    "          'clavicula_x_dif','clavicula_y_dif','clavicula_z_dif', \\\n",
    "          'scapula_x_dif','scapula_y_dif','scapula_z_dif', \\\n",
    "          'humerus_x_dif', 'humerus_y_dif', 'humerus_z_dif'\n",
    "         ]\n",
    "\n",
    "df_cleaned['bias'] = 1\n",
    "\n",
    "# split oorsprong kolom in onderdelen\n",
    "x,y = df_cleaned['Oorsprong'].str.split(\".\").str #Oordprong word vertaald naar een string en wordt gesplits op de punt\n",
    "df_cleaned['cat'],df_cleaned['pat'],df_cleaned['meting'],df_cleaned['oef'] = x.str.split(\"_\").str #4 categorieen gemaakt obv file name\n",
    "df_cleaned['cat'] = [ int(x[3:]) for x in df_cleaned['cat']] #voor elk 3+ element in de kolom wordt vertaald naar een int\n",
    "df_cleaned['meting'] = [ int(x[6:]) for x in df_cleaned['meting']] \n",
    "df_cleaned['oef'] = [ int(x[3:]) for x in df_cleaned['oef']] \n",
    "df_cleaned['pat'] = [ int(x[3:]) for x in df_cleaned['pat']] \n",
    "#na deze regels te hebben uitgevoerd zijn er nieuwe categorieen met ints.\n",
    "\n",
    "df_cleaned['pat'] = df_cleaned['cat']*1000+df_cleaned['pat'] #geef elke patient een uniek nummer\n",
    "\n",
    "#maak boolean kolom per categorie\n",
    "df_cleaned['c4'] = ['Cat4' in vincent for vincent in df_cleaned['Oorsprong']]\n",
    "df_cleaned['c3'] = ['Cat3' in vincent for vincent in df_cleaned['Oorsprong']]\n",
    "df_cleaned['c2'] = ['Cat2' in vincent for vincent in df_cleaned['Oorsprong']]\n",
    "df_cleaned['c1'] = ['Cat1' in vincent for vincent in df_cleaned['Oorsprong']]\n",
    "\n",
    "#df_cleaned = df_cleaned[~df_cleaned.c3]\n",
    "#df_cleaned = df_cleaned[~df_cleaned.c2]\n",
    "\n",
    "#Xcolumns = ['bias']\n",
    "#Xcolumns.extend(param)\n",
    "\n",
    "#X = df_cleaned[Xcolumns]\n",
    "#y = df_cleaned['c4']\n",
    "y = df_cleaned['cat']\n",
    "\n",
    "Cleaned_train, Cleaned_test, y_tmp, y_tmp2 = train_test_split(df_cleaned, y, test_size = 0.2, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VisualizeItems(items, x, y, z):\n",
    "    for i in items:\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            splitted = i.split('.')[0].split('_')\n",
    "            Cat = splitted[0]\n",
    "            pat = splitted[1]\n",
    "            meting = splitted[2]\n",
    "            oef = splitted[3]\n",
    "        except(IndexError):\n",
    "            oef = 'failed'\n",
    "        print(i)\n",
    "        data = HeaderMaker(i)\n",
    "\n",
    "        xlist = data[x]\n",
    "        ylist = data[y]\n",
    "        zlist = data[z]\n",
    "        \n",
    "        \n",
    "        index = 0\n",
    "        NewList = []\n",
    "        for num, ColumnList in enumerate([xlist, ylist, zlist]):\n",
    "            templist = []\n",
    "            for index in range(1, len(ColumnList)):\n",
    "                try:\n",
    "                    vorige = ColumnList.iloc[index-1]\n",
    "                    volgende = ColumnList.iloc[index+1]\n",
    "                    templist.append(vorige - volgende)\n",
    "                except(IndexError):\n",
    "                    templist.append(0)\n",
    "                    \n",
    "            NewList.append({'x':list(ColumnList[1:]), 'y':templist})\n",
    "#             return NewList\n",
    "#             break\n",
    "        \n",
    "                \n",
    "        for item in NewList:\n",
    "            print('NewItems')\n",
    "            fig = plt.figure()\n",
    "            ax = fig.gca()\n",
    "            for i in range(0, len(item['x']), 1):\n",
    "                plt.plot(item['x'][i:i+2], item['y'][i:i+2], 'ro-')\n",
    "            cricle = plt.Circle((item['x'][0], item['y'][0]), 2, color='y')\n",
    "            ax.add_artist(cricle)\n",
    "            plt.title('cat: %s pat: %s oef: %s meting: %s' % (Cat, pat, oef, meting))\n",
    "            \n",
    "            TotaleOppervlakte = 0\n",
    "            for index, CurrentXValue in enumerate(item['x']):\n",
    "                if index == 0:\n",
    "                    continue\n",
    "                \n",
    "                PreviousXValue = item['x'][index - 1]\n",
    "                \n",
    "                if CurrentXValue > PreviousXValue:\n",
    "                    Multiplier = 1\n",
    "                elif CurrentXValue < PreviousXValue:\n",
    "                    Multiplier = -1\n",
    "                else:\n",
    "                    # Zelfde X waarde, dus geen oppervlakte\n",
    "                    continue\n",
    "                \n",
    "                LowestValue = min(item['y'])\n",
    "                CurrentyValue = item['y'][index]\n",
    "                PreviousyValue = item['y'][index - 1]\n",
    "                \n",
    "                # Vierkant oppervlakte berekenen\n",
    "                breedte = abs(abs(CurrentXValue) - abs(PreviousXValue))\n",
    "                hoogte = abs(LowestValue) + abs(min([CurrentyValue, PreviousyValue]))\n",
    "                Oppervlakte = breedte * hoogte\n",
    "                \n",
    "                # Driehoek oppervlakte berekeken\n",
    "                hoogteDrie = abs(CurrentyValue - PreviousyValue)\n",
    "                Oppervlakte = Oppervlakte + 0.5 * hoogteDrie * breedte\n",
    "                \n",
    "                TotaleOppervlakte += Oppervlakte * Multiplier\n",
    "            plt.text(0,0, str(abs(TotaleOppervlakte)))\n",
    "                \n",
    "            \n",
    "# #         plt.ylim((-180,180))\n",
    "#         plt.plot(NewList[0], color = 'red')\n",
    "#         plt.plot(NewList[1], color = 'blue')\n",
    "#         plt.plot(NewList[2], color = 'green')\n",
    "#         plt.legend()\n",
    "        \n",
    "    plt.tight_layout()  \n",
    "    plt.show()\n",
    "\n",
    "def CreateList(keywordslist):\n",
    "    allitems = listdir('/data/ortho/Cleaned Train/')\n",
    "    filteredlist = []\n",
    "    for i in keywordslist:\n",
    "        for x in allitems:\n",
    "            if (i in x):\n",
    "                filteredlist.append(x)\n",
    "        allitems = filteredlist\n",
    "        filteredlist = []\n",
    "    finallist = []\n",
    "    for i in allitems:\n",
    "        finallist.append('/data/ortho/Cleaned Train/%s' % i)\n",
    "    return finallist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trueval = 'c3'\n",
    "\n",
    "Cleaned_train = Cleaned_train[~Cleaned_train.c1]\n",
    "Cleaned_train = Cleaned_train[~Cleaned_train.c2]\n",
    "\n",
    "Xcolumns = ['bias']\n",
    "Xcolumns.extend(param)\n",
    "\n",
    "X_train = Cleaned_train[Xcolumns]\n",
    "y_train = Cleaned_train[trueval]\n",
    "\n",
    "Cleaned_test = Cleaned_test[~Cleaned_test.c1]\n",
    "Cleaned_test = Cleaned_test[~Cleaned_test.c2]\n",
    "\n",
    "X_test = Cleaned_test[Xcolumns]\n",
    "y_test = Cleaned_test[trueval]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_true = y_test\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "TN, FP, FN, TP = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "print(lr.coef_[0])\n",
    "\n",
    "tab = [[\"pred pos\", TP, FP], [\"pred neg\", FN, TN]]\n",
    "print(pd.DataFrame(tab, columns=[\"\", \"pos\", \"neg\"]))\n",
    "print()\n",
    "print(\"recall: \", recall_score(y_true, y_pred))\n",
    "print(\"precision: \", precision_score(y_true, y_pred))\n",
    "print(\"accuracy: \", accuracy_score(y_true, y_pred.round().astype(bool)))\n",
    "print('\\n\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.round().astype(bool)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
